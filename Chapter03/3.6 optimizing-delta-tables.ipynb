{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0950057a-c8b8-4ebf-95ee-fa471b189a55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from delta import  # Delta Lake 라이브러리 임포트 configure_spark_with_delta_pip, DeltaTable\n",
    "from pyspark.sql import SparkSession  # Spark SQL 작업을 위한 SparkSession 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b211680-15d4-4f8a-863d-e88f041671db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-c41fc6a7-bc07-4032-97cf-4b411b9f4a83;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 397ms :: artifacts dl 17ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-c41fc6a7-bc07-4032-97cf-4b411b9f4a83\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/8ms)\n",
      "24/02/04 17:13:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "builder = (SparkSession.builder  # SparkSession 빌더 패턴 시작\n",
    "           .appName(\"optimize-delta-table\")  # 애플리케이션 이름 설정\n",
    "           .master(\"spark://spark-master:7077\")  # Spark 마스터 URL 설정\n",
    "           .config(\"spark.executor.memory\", \"512m\")  # Spark 설정 옵션\n",
    "           .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")  # Spark 설정 옵션\n",
    "           .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")  # Spark 설정 옵션)\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()  # SparkSession 생성 또는 기존 세션 반환\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")  # 로그 레벨을 ERROR로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdaf277c-6331-4415-88f1-2c47771e215f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext sparksql_magic\n",
    "%config SparkSql.limit=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e26449-e04a-4cf5-a42f-5594943bd3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# For PySpark:\n",
    "df = spark.read.format(\"delta\").load(  # 파일 로드\"/opt/workspace/data/delta_lake/netflix_titles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7155a926-8214-47ad-bf6e-74a7521cc8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+---------------+--------------------+-------------+------------------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|               title|       director|                cast|      country|        date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+------------------+------------+------+---------+--------------------+--------------------+\n",
      "|     s1|  Movie|Dick Johnson Is Dead|Kirsten Johnson|                null|United States|September 25, 2021|        2020| PG-13|   90 min|       Documentaries|As her father nea...|\n",
      "|     s2|TV Show|       Blood & Water|               |Ama Qamata, Khosi...| South Africa|September 24, 2021|        2021| TV-MA|2 Seasons|International TV ...|After crossing pa...|\n",
      "|     s3|TV Show|           Ganglands|Julien Leclercq|Sami Bouajila, Tr...|         null|September 24, 2021|        2021| TV-MA| 1 Season|Crime TV Shows, I...|To protect his fa...|\n",
      "|     s4|TV Show|Jailbirds New Orl...|               |                null|         null|September 24, 2021|        2021| TV-MA| 1 Season|Docuseries, Reali...|Feuds, flirtation...|\n",
      "|     s5|TV Show|        Kota Factory|               |Mayur More, Jiten...|        India|September 24, 2021|        2021| TV-MA|2 Seasons|International TV ...|In a city of coac...|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+------------------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c7df3ad-58bf-4fcc-a9d1-97e40e536845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">version</td><td style=\"font-weight: bold\">timestamp</td><td style=\"font-weight: bold\">userId</td><td style=\"font-weight: bold\">userName</td><td style=\"font-weight: bold\">operation</td><td style=\"font-weight: bold\">operationParameters</td><td style=\"font-weight: bold\">job</td><td style=\"font-weight: bold\">notebook</td><td style=\"font-weight: bold\">clusterId</td><td style=\"font-weight: bold\">readVersion</td><td style=\"font-weight: bold\">isolationLevel</td><td style=\"font-weight: bold\">isBlindAppend</td><td style=\"font-weight: bold\">operationMetrics</td><td style=\"font-weight: bold\">userMetadata</td><td style=\"font-weight: bold\">engineInfo</td></tr><tr><td>3</td><td>2024-02-04 17:05:38.590000</td><td>null</td><td>null</td><td>UPDATE</td><td>{&#x27;predicate&#x27;: &#x27;[&quot;isnull(director#40)&quot;]&#x27;}</td><td>null</td><td>null</td><td>null</td><td>2</td><td>Serializable</td><td>False</td><td>{&#x27;numRemovedBytes&#x27;: &#x27;1960782&#x27;, &#x27;numAddedFiles&#x27;: &#x27;1&#x27;, &#x27;scanTimeMs&#x27;: &#x27;2915&#x27;, &#x27;numCopiedRows&#x27;: &#x27;6172&#x27;, &#x27;executionTimeMs&#x27;: &#x27;5820&#x27;, &#x27;numAddedChangeFiles&#x27;: &#x27;0&#x27;, &#x27;numAddedBytes&#x27;: &#x27;1963749&#x27;, &#x27;numUpdatedRows&#x27;: &#x27;2634&#x27;, &#x27;numRemovedFiles&#x27;: &#x27;1&#x27;, &#x27;rewriteTimeMs&#x27;: &#x27;2899&#x27;}</td><td>null</td><td>Apache-Spark/3.4.1 Delta-Lake/2.4.0</td></tr><tr><td>2</td><td>2024-02-04 17:04:16.904000</td><td>null</td><td>null</td><td>SET TBLPROPERTIES</td><td>{&#x27;properties&#x27;: &#x27;{&quot;delta.logRetentionDuration&quot;:&quot;interval 60 days&quot;,&quot;delta.deletedFileRetentionDuration&quot;:&quot;interval 14 days&quot;}&#x27;}</td><td>null</td><td>null</td><td>null</td><td>1</td><td>Serializable</td><td>True</td><td>{}</td><td>null</td><td>Apache-Spark/3.4.1 Delta-Lake/2.4.0</td></tr><tr><td>1</td><td>2024-02-04 17:03:13.178000</td><td>null</td><td>null</td><td>CREATE OR REPLACE TABLE AS SELECT</td><td>{&#x27;description&#x27;: None, &#x27;partitionBy&#x27;: &#x27;[]&#x27;, &#x27;properties&#x27;: &#x27;{}&#x27;, &#x27;isManaged&#x27;: &#x27;false&#x27;}</td><td>null</td><td>null</td><td>null</td><td>0</td><td>Serializable</td><td>False</td><td>{&#x27;numOutputRows&#x27;: &#x27;8806&#x27;, &#x27;numOutputBytes&#x27;: &#x27;1960782&#x27;, &#x27;numFiles&#x27;: &#x27;1&#x27;}</td><td>null</td><td>Apache-Spark/3.4.1 Delta-Lake/2.4.0</td></tr><tr><td>0</td><td>2024-02-04 17:03:06.818000</td><td>null</td><td>null</td><td>CREATE OR REPLACE TABLE</td><td>{&#x27;description&#x27;: None, &#x27;partitionBy&#x27;: &#x27;[]&#x27;, &#x27;properties&#x27;: &#x27;{}&#x27;, &#x27;isManaged&#x27;: &#x27;false&#x27;}</td><td>null</td><td>null</td><td>null</td><td>null</td><td>Serializable</td><td>True</td><td>{}</td><td>null</td><td>Apache-Spark/3.4.1 Delta-Lake/2.4.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "DESCRIBE HISTORY \"/opt/workspace/data/delta_lake/netflix_titles\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64224e06-6e39-4c58-9c6a-a46e824e4735",
   "metadata": {},
   "source": [
    "### Optimize performance with file management - Compaction (bin-packing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc47d67b-623f-43df-bf79-f4d1fd8efc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,numTableColumns:bigint,numTableColumnsWithStats:bigint>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltaTable = DeltaTable  # Delta 테이블 작업을 위한 클래스.forPath(spark, \"/opt/workspace/data/delta_lake/netflix_titles\")  \n",
    "# For Hive metastore-based tables: deltaTable = DeltaTable  # Delta 테이블 작업을 위한 클래스.forName(spark, tableName)\n",
    "deltaTable.optimize().executeCompaction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e699fafb-5d1d-48a0-9e8c-a70fe6c68362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">path</td><td style=\"font-weight: bold\">metrics</td></tr><tr><td>file:/opt/workspace/data/delta_lake/netflix_titles</td><td>Row(numFilesAdded=0, numFilesRemoved=0, filesAdded=Row(min=None, max=None, avg=0.0, totalFiles=0, totalSize=0), filesRemoved=Row(min=None, max=None, avg=0.0, totalFiles=0, totalSize=0), partitionsOptimized=0, zOrderStats=None, numBatches=0, totalConsideredFiles=1, totalFilesSkipped=1, preserveInsertionOrder=False, numFilesSkippedToReduceWriteAmplification=0, numBytesSkippedToReduceWriteAmplification=0, startTimeMs=1707066836428, endTimeMs=0, totalClusterParallelism=2, totalScheduledTasks=0, autoCompactParallelismStats=None, deletionVectorStats=None, numTableColumns=12, numTableColumnsWithStats=12)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "-- Optimizes the path-based Delta Lake table\n",
    "OPTIMIZE \"/opt/workspace/data/delta_lake/netflix_titles\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ea1cb-9d07-4c89-94a6-75b5f7225ae9",
   "metadata": {},
   "source": [
    "### Data skipping - Z-Ordering (multi-dimensional clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5482bc0-b32d-45c6-9ad3-1d44f9071a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,numTableColumns:bigint,numTableColumnsWithStats:bigint>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltaTable = DeltaTable  # Delta 테이블 작업을 위한 클래스.forPath(spark, \"/opt/workspace/data/delta_lake/netflix_titles\")  # path-based table\n",
    "# For Hive metastore-based tables: deltaTable = DeltaTable  # Delta 테이블 작업을 위한 클래스.forName(spark, tableName)\n",
    "deltaTable.optimize().executeZOrderBy(\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0e3baaa-b70c-40f1-be0f-6edf7714e398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">path</td><td style=\"font-weight: bold\">metrics</td></tr><tr><td>file:/opt/workspace/data/delta_lake/netflix_titles</td><td>Row(numFilesAdded=1, numFilesRemoved=1, filesAdded=Row(min=1963749, max=1963749, avg=1963749.0, totalFiles=1, totalSize=1963749), filesRemoved=Row(min=1963749, max=1963749, avg=1963749.0, totalFiles=1, totalSize=1963749), partitionsOptimized=1, zOrderStats=Row(strategyName=&#x27;all&#x27;, inputCubeFiles=Row(num=0, size=0), inputOtherFiles=Row(num=1, size=1963749), inputNumCubes=0, mergedFiles=Row(num=1, size=1963749), numOutputCubes=1, mergedNumCubes=None), numBatches=1, totalConsideredFiles=1, totalFilesSkipped=0, preserveInsertionOrder=False, numFilesSkippedToReduceWriteAmplification=0, numBytesSkippedToReduceWriteAmplification=0, startTimeMs=1707066851774, endTimeMs=0, totalClusterParallelism=2, totalScheduledTasks=0, autoCompactParallelismStats=None, deletionVectorStats=None, numTableColumns=12, numTableColumnsWithStats=12)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "OPTIMIZE \"/opt/workspace/data/delta_lake/netflix_titles\" ZORDER BY (country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea678a08-59f1-4a1b-99c2-94fe84d7eb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">version</td><td style=\"font-weight: bold\">timestamp</td><td style=\"font-weight: bold\">userId</td><td style=\"font-weight: bold\">userName</td><td style=\"font-weight: bold\">operation</td><td style=\"font-weight: bold\">operationParameters</td><td style=\"font-weight: bold\">job</td><td style=\"font-weight: bold\">notebook</td><td style=\"font-weight: bold\">clusterId</td><td style=\"font-weight: bold\">readVersion</td><td style=\"font-weight: bold\">isolationLevel</td><td style=\"font-weight: bold\">isBlindAppend</td><td style=\"font-weight: bold\">operationMetrics</td><td style=\"font-weight: bold\">userMetadata</td><td style=\"font-weight: bold\">engineInfo</td></tr><tr><td>5</td><td>2024-02-04 17:14:08.504000</td><td>null</td><td>null</td><td>OPTIMIZE</td><td>{&#x27;predicate&#x27;: &#x27;[]&#x27;, &#x27;zOrderBy&#x27;: &#x27;[&quot;country&quot;]&#x27;}</td><td>null</td><td>null</td><td>null</td><td>4</td><td>SnapshotIsolation</td><td>False</td><td>{&#x27;numRemovedBytes&#x27;: &#x27;1963749&#x27;, &#x27;p50FileSize&#x27;: &#x27;1963749&#x27;, &#x27;p25FileSize&#x27;: &#x27;1963749&#x27;, &#x27;numAddedFiles&#x27;: &#x27;1&#x27;, &#x27;minFileSize&#x27;: &#x27;1963749&#x27;, &#x27;p75FileSize&#x27;: &#x27;1963749&#x27;, &#x27;numDeletionVectorsRemoved&#x27;: &#x27;0&#x27;, &#x27;numAddedBytes&#x27;: &#x27;1963749&#x27;, &#x27;maxFileSize&#x27;: &#x27;1963749&#x27;, &#x27;numRemovedFiles&#x27;: &#x27;1&#x27;}</td><td>null</td><td>Apache-Spark/3.4.1 Delta-Lake/2.4.0</td></tr><tr><td>4</td><td>2024-02-04 17:14:01.672000</td><td>null</td><td>null</td><td>OPTIMIZE</td><td>{&#x27;predicate&#x27;: &#x27;[]&#x27;, &#x27;zOrderBy&#x27;: &#x27;[&quot;country&quot;]&#x27;}</td><td>null</td><td>null</td><td>null</td><td>3</td><td>SnapshotIsolation</td><td>False</td><td>{&#x27;numRemovedBytes&#x27;: &#x27;1963749&#x27;, &#x27;p50FileSize&#x27;: &#x27;1963749&#x27;, &#x27;p25FileSize&#x27;: &#x27;1963749&#x27;, &#x27;numAddedFiles&#x27;: &#x27;1&#x27;, &#x27;minFileSize&#x27;: &#x27;1963749&#x27;, &#x27;p75FileSize&#x27;: &#x27;1963749&#x27;, &#x27;numDeletionVectorsRemoved&#x27;: &#x27;0&#x27;, &#x27;numAddedBytes&#x27;: &#x27;1963749&#x27;, &#x27;maxFileSize&#x27;: &#x27;1963749&#x27;, &#x27;numRemovedFiles&#x27;: &#x27;1&#x27;}</td><td>null</td><td>Apache-Spark/3.4.1 Delta-Lake/2.4.0</td></tr><tr><td>3</td><td>2024-02-04 17:05:38.590000</td><td>null</td><td>null</td><td>UPDATE</td><td>{&#x27;predicate&#x27;: &#x27;[&quot;isnull(director#40)&quot;]&#x27;}</td><td>null</td><td>null</td><td>null</td><td>2</td><td>Serializable</td><td>False</td><td>{&#x27;numRemovedBytes&#x27;: &#x27;1960782&#x27;, &#x27;numAddedFiles&#x27;: &#x27;1&#x27;, &#x27;scanTimeMs&#x27;: &#x27;2915&#x27;, &#x27;numCopiedRows&#x27;: &#x27;6172&#x27;, &#x27;executionTimeMs&#x27;: &#x27;5820&#x27;, &#x27;numAddedChangeFiles&#x27;: &#x27;0&#x27;, &#x27;numAddedBytes&#x27;: &#x27;1963749&#x27;, &#x27;numUpdatedRows&#x27;: &#x27;2634&#x27;, &#x27;numRemovedFiles&#x27;: &#x27;1&#x27;, &#x27;rewriteTimeMs&#x27;: &#x27;2899&#x27;}</td><td>null</td><td>Apache-Spark/3.4.1 Delta-Lake/2.4.0</td></tr><tr><td>2</td><td>2024-02-04 17:04:16.904000</td><td>null</td><td>null</td><td>SET TBLPROPERTIES</td><td>{&#x27;properties&#x27;: &#x27;{&quot;delta.logRetentionDuration&quot;:&quot;interval 60 days&quot;,&quot;delta.deletedFileRetentionDuration&quot;:&quot;interval 14 days&quot;}&#x27;}</td><td>null</td><td>null</td><td>null</td><td>1</td><td>Serializable</td><td>True</td><td>{}</td><td>null</td><td>Apache-Spark/3.4.1 Delta-Lake/2.4.0</td></tr><tr><td>1</td><td>2024-02-04 17:03:13.178000</td><td>null</td><td>null</td><td>CREATE OR REPLACE TABLE AS SELECT</td><td>{&#x27;description&#x27;: None, &#x27;partitionBy&#x27;: &#x27;[]&#x27;, &#x27;properties&#x27;: &#x27;{}&#x27;, &#x27;isManaged&#x27;: &#x27;false&#x27;}</td><td>null</td><td>null</td><td>null</td><td>0</td><td>Serializable</td><td>False</td><td>{&#x27;numOutputRows&#x27;: &#x27;8806&#x27;, &#x27;numOutputBytes&#x27;: &#x27;1960782&#x27;, &#x27;numFiles&#x27;: &#x27;1&#x27;}</td><td>null</td><td>Apache-Spark/3.4.1 Delta-Lake/2.4.0</td></tr><tr><td>0</td><td>2024-02-04 17:03:06.818000</td><td>null</td><td>null</td><td>CREATE OR REPLACE TABLE</td><td>{&#x27;description&#x27;: None, &#x27;partitionBy&#x27;: &#x27;[]&#x27;, &#x27;properties&#x27;: &#x27;{}&#x27;, &#x27;isManaged&#x27;: &#x27;false&#x27;}</td><td>null</td><td>null</td><td>null</td><td>null</td><td>Serializable</td><td>True</td><td>{}</td><td>null</td><td>Apache-Spark/3.4.1 Delta-Lake/2.4.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "DESCRIBE HISTORY \"/opt/workspace/data/delta_lake/netflix_titles\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c091e-9fea-42a9-bded-8eca88b6a47c",
   "metadata": {},
   "source": [
    "### Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c48f167d-e113-471c-9017-188be0ae5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 읽기 the data as a DataFrame\n",
    "df = (spark.read.format(\"json\")  # JSON 형식으로 데이터 읽기\n",
    "      .option(\"multiLine\", \"true\")  # 여러 줄 JSON 처리\n",
    "      .load(  # 파일 로드\"../data/nobel_prizes.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c692d5-c888-4aa9-821b-984c080a0bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category: string (nullable = true)\n",
      " |-- laureates: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- firstname: string (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- motivation: string (nullable = true)\n",
      " |    |    |-- share: string (nullable = true)\n",
      " |    |    |-- surname: string (nullable = true)\n",
      " |-- overallMotivation: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()  # DataFrame 스키마 구조 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4655ebd-c6fb-4e73-8571-f86b08a82885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 쓰기 the data to a Delta Lake table with partitioning\n",
    "(df.write.format(\"delta\")  # Delta Lake 형식으로 저장\n",
    " .mode(\"overwrite\")  # 기존 데이터 덮어쓰기\n",
    " .partitionBy(\"year\")\n",
    " .save(\"/opt/workspace/data/delta_lake/nobel_prizes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3a96f39-5ef6-4836-9c2f-d2c1a65b8197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------------+----+\n",
      "|  category|           laureates|overallMotivation|year|\n",
      "+----------+--------------------+-----------------+----+\n",
      "| chemistry|[{Paul J., 246, \"...|             null|1974|\n",
      "| economics|[{Gunnar, 684, \"f...|             null|1974|\n",
      "|literature|[{Eyvind, 649, \"f...|             null|1974|\n",
      "|     peace|[{Seán, 532, \"for...|             null|1974|\n",
      "|   physics|[{Martin, 100, \"f...|             null|1974|\n",
      "|  medicine|[{Albert, 403, \"f...|             null|1974|\n",
      "| chemistry|[{Svante, 162, \"i...|             null|1903|\n",
      "|literature|[{Bjørnstjerne, 5...|             null|1903|\n",
      "|     peace|[{Randal, 466, \"f...|             null|1903|\n",
      "|   physics|[{Henri, 4, \"in r...|             null|1903|\n",
      "|  medicine|[{Niels Ryberg, 2...|             null|1903|\n",
      "| chemistry|[{Alfred, 174, \"i...|             null|1913|\n",
      "|literature|[{Rabindranath, 5...|             null|1913|\n",
      "|     peace|[{Henri, 481, \"fo...|             null|1913|\n",
      "|   physics|[{Heike, 18, \"for...|             null|1913|\n",
      "|  medicine|[{Charles, 307, \"...|             null|1913|\n",
      "| chemistry|[{Max F., 226, \"f...|             null|1962|\n",
      "|literature|[{John, 634, \"for...|             null|1962|\n",
      "|     peace|[{Linus, 217, \"fo...|             null|1962|\n",
      "|   physics|[{Lev, 77, \"for h...|             null|1962|\n",
      "+----------+--------------------+-----------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the partitioned table\n",
    "df = spark.read.format(\"delta\").load(  # 파일 로드\"/opt/workspace/data/delta_lake/nobel_prizes\")\n",
    "df.show()  # DataFrame 내용 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f09faf9-527c-4b78-ab54-7271ff8c1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()  # Spark 세션 종료 - 리소스 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58948e42-f877-4926-acfd-842b2f79ee61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}