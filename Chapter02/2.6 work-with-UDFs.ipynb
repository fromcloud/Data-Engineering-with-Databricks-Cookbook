{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d841128-719a-4d79-b52f-9625d060a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession  # Spark SQL 작업을 위한 SparkSession 임포트\n",
    "from pyspark.sql.functions import  # Spark SQL 함수들 임포트 explode, col\n",
    "\n",
    "# UDF(사용자 정의 함수) 작업을 위한 SparkSession 생성\n",
    "spark = (SparkSession.builder  # SparkSession 빌더 패턴 시작\n",
    "         .appName(\"write-udfs\")  # UDF 작업 애플리케이션\n",
    "         .master(\"spark://spark-master:7077\")  # Spark 마스터 연결\n",
    "         .config(\"spark.executor.memory\", \"512m\")  # 실행자 메모리 설정\n",
    "         .getOrCreate())  # 세션 생성 또는 기존 세션 사용\n",
    "\n",
    "# 로그 레벨을 ERROR로 설정\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")  # 로그 레벨을 ERROR로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc7b819-4bd8-4398-a8d7-44b688def90f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# UDF 예제를 위한 노벨상 데이터 로드\n",
    "df = (spark.read.format(\"json\")  # JSON 형식 지정\n",
    "      .option(\"multiLine\", \"true\")  # 여러 줄 JSON 처리\n",
    "      .load(\"../data/nobel_prizes.json\"))  # 노벨상 데이터 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7146577-7afc-4498-9a94-a68a21c89d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# UDF 예제를 위한 데이터 전처리 - 중첩 구조 평면화 및 필터링\n",
    "df_flattened = (\n",
    "    df\n",
    "    .withColumn(\"laureates\",explode(col(\"laureates\")))  # 수상자 배열을 개별 행으로 분해\n",
    "    .select(col(\"category\")  # 카테고리 선택\n",
    "            ,col(\"year\")  # 연도 선택\n",
    "            ,col(\"overallMotivation\")  # 전체 동기 선택\n",
    "            ,col(\"laureates.id\")  # 수상자 ID 선택\n",
    "            ,col(\"laureates.firstname\")  # 수상자 이름 선택\n",
    "            ,col(\"laureates.surname\")  # 수상자 성 선택\n",
    "            ,col(\"laureates.share\")  # 수상 비율 선택\n",
    "            ,col(\"laureates.motivation\"))  # 수상 이유 선택\n",
    "    .filter(col(\"laureates.firstname\").isNotNull() & col(\"laureates.surname\").isNotNull()))  # 이름과 성이 모두 있는 데이터만 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64a21a16-b27a-4490-bad0-612649af6826",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 사용자 정의 함수(UDF) 정의 - 이름과 성을 결합하는 함수\n",
    "def concat(  # 문자열 연결first_name, last_name):\n",
    "    \"\"\"\n",
    "    이름과 성을 겵백으로 구분하여 결합하는 함수\n",
    "    \"\"\"\n",
    "    return first_name + \" \" + last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "200b31e2-9517-4c09-a2ef-0f0330759860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import  # Spark SQL 함수들 임포트 udf\n",
    "# Python 함수를 Spark UDF로 변환 - 기본 방식(반환 타입 자동 추론)\n",
    "concat_udf = udf(  # 사용자 정의 함수 생성concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1454b0c4-728c-44a2-bdbe-22d988f6cd37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import  # Spark SQL 데이터 타입 임포트 StringType\n",
    "# 명시적 반환 타입을 지정한 UDF 생성 - 성능 최적화를 위해 권장\n",
    "concat_udf = udf(  # 사용자 정의 함수 생성concat, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "640e3130-4958-4c6d-a56b-86eabb53637c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# UDF를 사용하여 새로운 컴럼 추가 - 이름과 성을 결합한 전체 이름\n",
    "df_flattened = df_flattened.withColumn(  # 새 컬럼 추가 또는 기존 컬럼 수정\"full_name\", concat_udf(df_flattened[\"firstname\"], df_flattened[\"surname\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8122652-c053-4a4f-a43a-00c97dbdac6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+--------------------+----+----------+-----------+-----+--------------------+-----------------+\n",
      "|  category|year|   overallMotivation|  id| firstname|    surname|share|          motivation|        full_name|\n",
      "+----------+----+--------------------+----+----------+-----------+-----+--------------------+-----------------+\n",
      "| chemistry|2022|                null|1015|   Carolyn|   Bertozzi|    3|\"for the developm...| Carolyn Bertozzi|\n",
      "| chemistry|2022|                null|1016|    Morten|     Meldal|    3|\"for the developm...|    Morten Meldal|\n",
      "| chemistry|2022|                null| 743|     Barry|  Sharpless|    3|\"for the developm...|  Barry Sharpless|\n",
      "| economics|2022|                null|1021|       Ben|   Bernanke|    3|\"for research on ...|     Ben Bernanke|\n",
      "| economics|2022|                null|1022|   Douglas|    Diamond|    3|\"for research on ...|  Douglas Diamond|\n",
      "| economics|2022|                null|1023|    Philip|     Dybvig|    3|\"for research on ...|    Philip Dybvig|\n",
      "|literature|2022|                null|1017|     Annie|     Ernaux|    1|\"for the courage ...|     Annie Ernaux|\n",
      "|     peace|2022|                null|1018|      Ales|Bialiatski |    3|\"The Peace Prize ...| Ales Bialiatski |\n",
      "|   physics|2022|                null|1012|     Alain|     Aspect|    3|\"for experiments ...|     Alain Aspect|\n",
      "|   physics|2022|                null|1014|     Anton|  Zeilinger|    3|\"for experiments ...|  Anton Zeilinger|\n",
      "|  medicine|2022|                null|1011|    Svante|      Pääbo|    1|\"for his discover...|     Svante Pääbo|\n",
      "| chemistry|2021|                null|1002|  Benjamin|       List|    2|\"for the developm...|    Benjamin List|\n",
      "| chemistry|2021|                null|1003|     David|  MacMillan|    2|\"for the developm...|  David MacMillan|\n",
      "| economics|2021|                null|1007|     David|       Card|    2|\"for his empirica...|       David Card|\n",
      "| economics|2021|                null|1008|    Joshua|    Angrist|    4|\"for their method...|   Joshua Angrist|\n",
      "| economics|2021|                null|1009|     Guido|     Imbens|    4|\"for their method...|     Guido Imbens|\n",
      "|literature|2021|                null|1004|Abdulrazak|     Gurnah|    1|\"for his uncompro...|Abdulrazak Gurnah|\n",
      "|     peace|2021|                null|1005|     Maria|      Ressa|    2|\"for their effort...|      Maria Ressa|\n",
      "|     peace|2021|                null|1006|    Dmitry|    Muratov|    2|\"for their effort...|   Dmitry Muratov|\n",
      "|   physics|2021|\"for groundbreaki...| 999|   Syukuro|     Manabe|    4|\"for the physical...|   Syukuro Manabe|\n",
      "+----------+----+--------------------+----+----------+-----------+-----+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# UDF가 적용된 DataFrame 출력 - full_name 컴럼 확인\n",
    "df_flattened.show()  # DataFrame 내용 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd6cffb-d945-4111-95dc-a0591070c82f",
   "metadata": {},
   "source": [
    "### Using UDFs in Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bbc615c-73ad-46fc-965f-cc3fba819342",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "|num|square_num|\n",
      "+---+----------+\n",
      "|  1|         1|\n",
      "|  2|         4|\n",
      "|  3|         9|\n",
      "|  4|        16|\n",
      "|  5|        25|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import  # Spark SQL 함수들 임포트 udf\n",
    "from pyspark.sql.types import  # Spark SQL 데이터 타입 임포트 IntegerType\n",
    "\n",
    "# Spark SQL에서 사용할 UDF 정의 - 숫자의 제곱 계산\n",
    "def square_udf(  # 사용자 정의 함수 생성x):\n",
    "    \"\"\"\n",
    "    입력값의 제곱을 반환하는 함수\n",
    "    \"\"\"\n",
    "    return x ** 2\n",
    "\n",
    "# UDF를 Spark SQL에서 사용할 수 있도록 등록\n",
    "spark.udf.register(  # UDF를 SQL에서 사용할 수 있도록 등록\"square\", square_udf, IntegerType())\n",
    "\n",
    "# 테스트용 DataFrame 생성\n",
    "df = spark.createDataFrame([(1,), (2,), (3,), (4,), (5,)], [\"num\"])\n",
    "\n",
    "# DataFrame을 임시 테이블로 등록하여 SQL 쿼리에서 사용 가능하게 설정\n",
    "df.createOrReplaceTempView(  # 임시 뷰 생성\"numbers\")\n",
    "# 등록된 UDF를 SQL 쿼리에서 사용\n",
    "result = spark.sql(  # SQL 쿼리 실행\"SELECT num, square(num) AS square_num FROM numbers\")\n",
    "\n",
    "# SQL UDF 사용 결과 출력\n",
    "result.show()  # DataFrame 내용 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab0b2436-32fc-4ce3-894c-26e902605baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark 세션 종료 - 리소스 정리\n",
    "spark.stop()  # Spark 세션 종료 - 리소스 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d052cef6-6ff8-49b1-98be-285d0305568f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}