{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d841128-719a-4d79-b52f-9625d060a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession  # Spark SQL 작업을 위한 SparkSession 임포트\n",
    "from pyspark.sql.functions import  # Spark SQL 함수들 임포트 explode, col, when\n",
    "\n",
    "spark = (SparkSession.builder  # SparkSession 빌더 패턴 시작\n",
    "         .appName(\"handle-nulls\")  # 애플리케이션 이름 설정\n",
    "         .master(\"spark://spark-master:7077\")  # Spark 마스터 URL 설정\n",
    "         .config(\"spark.executor.memory\", \"512m\")  # Spark 설정 옵션\n",
    "         .getOrCreate()  # SparkSession 생성 또는 기존 세션 반환)\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")  # 로그 레벨을 ERROR로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecc7b819-4bd8-4398-a8d7-44b688def90f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = (spark.read.format(\"json\")  # JSON 형식으로 데이터 읽기\n",
    "      .option(\"multiLine\", \"true\")  # 여러 줄 JSON 처리\n",
    "      .load(  # 파일 로드\"../data/nobel_prizes.json\"))\n",
    "\n",
    "df_flattened = (\n",
    "    df\n",
    "    .withColumn(  # 새 컬럼 추가 또는 기존 컬럼 수정\"laureates\",explode(col(\"laureates\")))\n",
    "    .select(  # 컬럼 선택col(\"category\")\n",
    "            ,col(  # 컬럼 참조\"year\")\n",
    "            ,col(  # 컬럼 참조\"overallMotivation\")\n",
    "            ,col(  # 컬럼 참조\"laureates.id\")\n",
    "            ,col(  # 컬럼 참조\"laureates.firstname\")\n",
    "            ,col(  # 컬럼 참조\"laureates.surname\")\n",
    "            ,col(  # 컬럼 참조\"laureates.share\")\n",
    "            ,col(  # 컬럼 참조\"laureates.motivation\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7146577-7afc-4498-9a94-a68a21c89d89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+--------------------+----+----------+----------+-----+--------------------+\n",
      "| category|year|   overallMotivation|  id| firstname|   surname|share|          motivation|\n",
      "+---------+----+--------------------+----+----------+----------+-----+--------------------+\n",
      "|  physics|2021|\"for groundbreaki...| 999|   Syukuro|    Manabe|    4|\"for the physical...|\n",
      "|  physics|2021|\"for groundbreaki...|1000|     Klaus|Hasselmann|    4|\"for the physical...|\n",
      "|  physics|2021|\"for groundbreaki...|1001|   Giorgio|    Parisi|    2|\"for the discover...|\n",
      "|  physics|2019|\"for contribution...| 973|     James|   Peebles|    2|\"for theoretical ...|\n",
      "|  physics|2019|\"for contribution...| 974|    Michel|     Mayor|    4|\"for the discover...|\n",
      "|  physics|2019|\"for contribution...| 975|    Didier|    Queloz|    4|\"for the discover...|\n",
      "|  physics|2018|\"for groundbreaki...| 960|    Arthur|    Ashkin|    2|\"for the optical ...|\n",
      "|  physics|2018|\"for groundbreaki...| 961|    Gérard|    Mourou|    4|\"for their method...|\n",
      "|  physics|2018|\"for groundbreaki...| 962|     Donna|Strickland|    4|\"for their method...|\n",
      "|chemistry|2003|\"for discoveries ...| 769|     Peter|      Agre|    2|\"for the discover...|\n",
      "|chemistry|2003|\"for discoveries ...| 770|  Roderick| MacKinnon|    2|\"for structural a...|\n",
      "|chemistry|2002|\"for the developm...| 756|   John B.|      Fenn|    4|\"for their develo...|\n",
      "|chemistry|2002|\"for the developm...| 757|    Koichi|    Tanaka|    4|\"for their develo...|\n",
      "|chemistry|2002|\"for the developm...| 758|      Kurt|  Wüthrich|    2|\"for his developm...|\n",
      "|  physics|2000|\"for basic work o...| 726|    Zhores|   Alferov|    4|\"for developing s...|\n",
      "|  physics|2000|\"for basic work o...| 727|   Herbert|   Kroemer|    4|\"for developing s...|\n",
      "|  physics|2000|\"for basic work o...| 728|      Jack|     Kilby|    2|\"for his part in ...|\n",
      "|  physics|1995|\"for pioneering e...| 147| Martin L.|      Perl|    2|\"for the discover...|\n",
      "|  physics|1995|\"for pioneering e...| 148| Frederick|    Reines|    2|\"for the detectio...|\n",
      "|  physics|1994|\"for pioneering c...| 145|Bertram N.|Brockhouse|    2|\"for the developm...|\n",
      "+---------+----+--------------------+----+----------+----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Dropping rows with null values\n",
    "df_dropna = df_flattened.dropna(  # null 값이 있는 행 제거)\n",
    "\n",
    "# 출력ing the DataFrame after dropping null values\n",
    "df_dropna.show()  # DataFrame 내용 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64a21a16-b27a-4490-bad0-612649af6826",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----------------+----+--------------------+-----------+-----+--------------------+\n",
      "|  category|year|overallMotivation|  id|           firstname|    surname|share|          motivation|\n",
      "+----------+----+-----------------+----+--------------------+-----------+-----+--------------------+\n",
      "| chemistry|2022|              N/A|1015|             Carolyn|   Bertozzi|    3|\"for the developm...|\n",
      "| chemistry|2022|              N/A|1016|              Morten|     Meldal|    3|\"for the developm...|\n",
      "| chemistry|2022|              N/A| 743|               Barry|  Sharpless|    3|\"for the developm...|\n",
      "| economics|2022|              N/A|1021|                 Ben|   Bernanke|    3|\"for research on ...|\n",
      "| economics|2022|              N/A|1022|             Douglas|    Diamond|    3|\"for research on ...|\n",
      "| economics|2022|              N/A|1023|              Philip|     Dybvig|    3|\"for research on ...|\n",
      "|literature|2022|              N/A|1017|               Annie|     Ernaux|    1|\"for the courage ...|\n",
      "|     peace|2022|              N/A|1018|                Ales|Bialiatski |    3|\"The Peace Prize ...|\n",
      "|     peace|2022|              N/A|1019|            Memorial|        N/A|    3|\"The Peace Prize ...|\n",
      "|     peace|2022|              N/A|1020|Center for Civil ...|        N/A|    3|\"The Peace Prize ...|\n",
      "|   physics|2022|              N/A|1012|               Alain|     Aspect|    3|\"for experiments ...|\n",
      "|   physics|2022|              N/A|1013|                 N/A|        N/A|    3|\"for experiments ...|\n",
      "|   physics|2022|              N/A|1014|               Anton|  Zeilinger|    3|\"for experiments ...|\n",
      "|  medicine|2022|              N/A|1011|              Svante|      Pääbo|    1|\"for his discover...|\n",
      "| chemistry|2021|              N/A|1002|            Benjamin|       List|    2|\"for the developm...|\n",
      "| chemistry|2021|              N/A|1003|               David|  MacMillan|    2|\"for the developm...|\n",
      "| economics|2021|              N/A|1007|               David|       Card|    2|\"for his empirica...|\n",
      "| economics|2021|              N/A|1008|              Joshua|    Angrist|    4|\"for their method...|\n",
      "| economics|2021|              N/A|1009|               Guido|     Imbens|    4|\"for their method...|\n",
      "|literature|2021|              N/A|1004|          Abdulrazak|     Gurnah|    1|\"for his uncompro...|\n",
      "+----------+----+-----------------+----+--------------------+-----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Filling null values with a specific value\n",
    "df_fillna = df_flattened.fillna(  # null 값 채우기\"N/A\")\n",
    "\n",
    "# 출력ing the DataFrame after filling null values\n",
    "df_fillna.show()  # DataFrame 내용 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "200b31e2-9517-4c09-a2ef-0f0330759860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----------------+----+--------------------+-----------+-----+--------------------+\n",
      "|  category|year|overallMotivation|  id|           firstname|    surname|share|          motivation|\n",
      "+----------+----+-----------------+----+--------------------+-----------+-----+--------------------+\n",
      "| chemistry|2022|                 |1015|             Carolyn|   Bertozzi|    3|\"for the developm...|\n",
      "| chemistry|2022|                 |1016|              Morten|     Meldal|    3|\"for the developm...|\n",
      "| chemistry|2022|                 | 743|               Barry|  Sharpless|    3|\"for the developm...|\n",
      "| economics|2022|                 |1021|                 Ben|   Bernanke|    3|\"for research on ...|\n",
      "| economics|2022|                 |1022|             Douglas|    Diamond|    3|\"for research on ...|\n",
      "| economics|2022|                 |1023|              Philip|     Dybvig|    3|\"for research on ...|\n",
      "|literature|2022|                 |1017|               Annie|     Ernaux|    1|\"for the courage ...|\n",
      "|     peace|2022|                 |1018|                Ales|Bialiatski |    3|\"The Peace Prize ...|\n",
      "|     peace|2022|                 |1019|            Memorial|           |    3|\"The Peace Prize ...|\n",
      "|     peace|2022|                 |1020|Center for Civil ...|           |    3|\"The Peace Prize ...|\n",
      "|   physics|2022|                 |1012|               Alain|     Aspect|    3|\"for experiments ...|\n",
      "|   physics|2022|                 |1013|                    |           |    3|\"for experiments ...|\n",
      "|   physics|2022|                 |1014|               Anton|  Zeilinger|    3|\"for experiments ...|\n",
      "|  medicine|2022|                 |1011|              Svante|      Pääbo|    1|\"for his discover...|\n",
      "| chemistry|2021|                 |1002|            Benjamin|       List|    2|\"for the developm...|\n",
      "| chemistry|2021|                 |1003|               David|  MacMillan|    2|\"for the developm...|\n",
      "| economics|2021|                 |1007|               David|       Card|    2|\"for his empirica...|\n",
      "| economics|2021|                 |1008|              Joshua|    Angrist|    4|\"for their method...|\n",
      "| economics|2021|                 |1009|               Guido|     Imbens|    4|\"for their method...|\n",
      "|literature|2021|                 |1004|          Abdulrazak|     Gurnah|    1|\"for his uncompro...|\n",
      "+----------+----+-----------------+----+--------------------+-----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replacing null values based on conditions\n",
    "df_replace = (\n",
    "    df_flattened.withColumn(  # 새 컬럼 추가 또는 기존 컬럼 수정\"category\", when(col(\"category\").isNull(), \"\").otherwise(col(\"category\")))\n",
    "    .withColumn(  # 새 컬럼 추가 또는 기존 컬럼 수정\"overallMotivation\", when(col(\"overallMotivation\").isNull(), \"\").otherwise(col(\"overallMotivation\")))\n",
    "    .withColumn(  # 새 컬럼 추가 또는 기존 컬럼 수정\"firstname\", when(col(\"firstname\").isNull(), \"\").otherwise(col(\"firstname\")))\n",
    "    .withColumn(  # 새 컬럼 추가 또는 기존 컬럼 수정\"surname\", when(col(\"surname\").isNull(), \"\").otherwise(col(\"surname\")))\n",
    "    .withColumn(  # 새 컬럼 추가 또는 기존 컬럼 수정\"year\", when(col(\"year\").isNull(), 9999).otherwise(col(\"year\"))))\n",
    "\n",
    "# 출력ing the DataFrame after replacing null values\n",
    "df_replace.show()  # DataFrame 내용 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd6cffb-d945-4111-95dc-a0591070c82f",
   "metadata": {},
   "source": [
    "### Handling null values in user-defined functions (UDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bbc615c-73ad-46fc-965f-cc3fba819342",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+--------------+\n",
      "| name| age|processed_name|\n",
      "+-----+----+--------------+\n",
      "| John|  25|          JOHN|\n",
      "|Alice|null|         ALICE|\n",
      "|  Bob|  30|           BOB|\n",
      "+-----+----+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession  # Spark SQL 작업을 위한 SparkSession 임포트\n",
    "from pyspark.sql.functions import  # Spark SQL 함수들 임포트 udf\n",
    "from pyspark.sql.types import  # Spark SQL 데이터 타입 임포트 StringType\n",
    "\n",
    "# Sample DataFrame with null values\n",
    "data = [(\"John\", 25), (\"Alice\", None), (\"Bob\", 30)]\n",
    "df = spark.createDataFrame(data, [\"name\", \"age\"])\n",
    "\n",
    "# Define a UDF to handle null values\n",
    "def process_name(name):\n",
    "    if name is None:\n",
    "        return \"Unknown\"\n",
    "    else:\n",
    "        return name.upper(  # 대문자로 변환)\n",
    "\n",
    "# Register the UDF\n",
    "process_name_udf = udf(  # 사용자 정의 함수 생성process_name, StringType())\n",
    "\n",
    "# 적용 the UDF to the DataFrame\n",
    "df_with_processed_names = df.withColumn(  # 새 컬럼 추가 또는 기존 컬럼 수정\"processed_name\", process_name_udf(df[\"name\"]))\n",
    "\n",
    "# 표시 the resulting DataFrame\n",
    "df_with_processed_names.show()  # DataFrame 내용 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df8a03d-b5e9-4f95-8de8-55cf28779035",
   "metadata": {},
   "source": [
    "### Handling null values in machine learning pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de3159c9-b1c7-44a2-9528-467f45bfcf52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----------------+\n",
      "| id|value|    imputed_value|\n",
      "+---+-----+-----------------+\n",
      "|  1|  2.0|              2.0|\n",
      "|  2| null|4.666666666666667|\n",
      "|  3|  5.0|              5.0|\n",
      "|  4| null|4.666666666666667|\n",
      "|  5|  7.0|              7.0|\n",
      "+---+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession  # Spark SQL 작업을 위한 SparkSession 임포트\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "# 생성 a sample DataFrame with missing values\n",
    "data = [\n",
    "    (1, 2.0),\n",
    "    (2, None),\n",
    "    (3, 5.0),\n",
    "    (4, None),\n",
    "    (5, 7.0)\n",
    "]\n",
    "df = spark.createDataFrame(data, [\"id\", \"value\"])\n",
    "\n",
    "# 생성 an instance of Imputer and specify the input/output columns\n",
    "imputer = Imputer(inputCols=[\"value\"], outputCols=[\"imputed_value\"])\n",
    "\n",
    "# Fit the imputer to the data and transform the DataFrame\n",
    "imputer_model = imputer.fit(df)\n",
    "imputed_df = imputer_model.transform(  # 배열 변환df)\n",
    "\n",
    "# 표시 the resulting DataFrame\n",
    "imputed_df.show()  # DataFrame 내용 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab0b2436-32fc-4ce3-894c-26e902605baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()  # Spark 세션 종료 - 리소스 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa06ec-2c1c-4662-9ffa-4c83498cda97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}