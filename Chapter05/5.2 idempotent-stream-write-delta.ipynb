{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82322425-528e-42ed-af6e-6a7218a8dc40",
   "metadata": {},
   "source": [
    "Before we start, we need to make sure that we have a Kafka cluster running and a topic that produces some streaming data. For simplicity, we will use a single-node Kafka cluster and a topic named `users`. Open the `5.0 user-gen-kafka.ipynb` notebook and execute the cell. This notebook produces a user record every few seconds and put it on a Kafka topic called `users`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54f45c54-0b95-4fd9-a180-fe3be96ab99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta import  # Delta Lake 라이브러리 임포트 configure_spark_with_delta_pip, DeltaTable\n",
    "from pyspark.sql import SparkSession  # Spark SQL 작업을 위한 SparkSession 임포트\n",
    "from pyspark.sql.functions import  # Spark SQL 함수들 임포트 col, from_json\n",
    "from pyspark.sql.types import  # Spark SQL 데이터 타입 임포트 StructType, StructField, IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7850eab-3759-491d-a70a-7a02977db101",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = (SparkSession.builder  # SparkSession 빌더 패턴 시작\n",
    "           .appName(\"idempotent-stream-write-delta\")  # 애플리케이션 이름 설정\n",
    "           .master(\"spark://spark-master:7077\")  # Spark 마스터 URL 설정\n",
    "           .config(\"spark.executor.memory\", \"512m\")  # Spark 설정 옵션\n",
    "           .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")  # Spark 설정 옵션\n",
    "           .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")  # Spark 설정 옵션)\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder,['org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1']).getOrCreate()  # SparkSession 생성 또는 기존 세션 반환\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")  # 로그 레벨을 ERROR로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd909d80-b814-4783-80b2-da272d2c79fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparksql_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext sparksql_magic\n"
     ]
    }
   ],
   "source": [
    "get_ipython().run_line_magic('load_ext', 'sparksql_magic')\n",
    "get_ipython().run_line_magic('config', 'SparkSql.limit=20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68da1a17-ffb1-445f-aee6-3f697ac7b3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "CREATE OR REPLACE TABLE default.users (\n",
    "    id INT,\n",
    "    name STRING,\n",
    "    age INT,\n",
    "    gender STRING,\n",
    "    country STRING \n",
    ") USING DELTA  # Delta Lake 테이블 생성 LOCATION '/opt/workspace/data/delta_lake/idempotent-stream-write-delta/users';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "228e8f56-4fd9-497a-947f-8ce968889dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = (spark.readStream  # 스트리밍 데이터 읽기\n",
    "      .format(\"kafka\")\n",
    "      .option(\"kafka.bootstrap.servers\", \"kafka:9092\")\n",
    "      .option(\"subscribe\", \"users\")\n",
    "      .option(\"startingOffsets\", \"earliest\")\n",
    "      .load(  # 파일 로드))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0e26449-e04a-4cf5-a42f-5594943bd3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = StructType  # 구조체 타입([\n",
    "    StructField  # 구조체 필드('id', IntegerType(), True),\n",
    "    StructField  # 구조체 필드('name', StringType(), True),\n",
    "    StructField  # 구조체 필드('age', IntegerType(), True),\n",
    "    StructField  # 구조체 필드('gender', StringType(), True),\n",
    "    StructField  # 구조체 필드('country', StringType(), True)])\n",
    "\n",
    "df = df.withColumn(  # 새 컬럼 추가 또는 기존 컬럼 수정'value', from_json(col('value').cast(\"STRING\"), schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8d3d68c-c3b0-4a8a-91b0-32366f2199fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.select(  # 컬럼 선택\n",
    "    col(  # 컬럼 참조'value.id').alias('id'),\n",
    "    col(  # 컬럼 참조'value.name').alias('name'),\n",
    "    col(  # 컬럼 참조'value.age').alias('age'),\n",
    "    col(  # 컬럼 참조'value.gender').alias('gender'),\n",
    "    col(  # 컬럼 참조'value.country').alias('country'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54d78eab-2e32-429b-954e-4140e7cafb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (df.writeStream  # 스트리밍 데이터 쓰기\n",
    "   .format(\"delta\")  # Delta Lake 형식으로 저장\n",
    "   .outputMode(  # 스트리밍 출력 모드 설정\"append\")\n",
    "   .option(\"checkpointLocation\", \"/opt/workspace/data/delta_lake/idempotent-stream-write-delta/users/_checkpoints/\")\n",
    "   .start(\"/opt/workspace/data/delta_lake/idempotent-stream-write-delta/users\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0bdd288-8690-42f5-b18a-7758fe2822a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 2) / 2]\r"
     ]
    }
   ],
   "source": [
    "# Define a function writing to two destinations\n",
    "app_id = 'idempotent-stream-write-delta'\n",
    "def writeToDeltaLakeTableIdempotent(batch_df, batch_id):\n",
    "    # location 1\n",
    "    (batch_df.filter(  # 데이터 필터링\"country IN ('India','China')\")\n",
    "     .write\n",
    "     .format(\"delta\")  # Delta Lake 형식으로 저장\n",
    "     .mode(\"append\")  # 기존 데이터에 추가\n",
    "     .option(\"txnVersion\", batch_id)\n",
    "     .option(\"txnAppId\", app_id)\n",
    "     .save(\"/opt/workspace/data/delta_lake/idempotent-stream-write-delta/user_asia\"))\n",
    "    # location 2\n",
    "    (batch_df.filter(  # 데이터 필터링\"country IN ('USA','Canada','Brazil')\")\n",
    "     .write\n",
    "     .format(\"delta\")  # Delta Lake 형식으로 저장\n",
    "     .mode(\"append\")  # 기존 데이터에 추가\n",
    "     .option(\"txnVersion\", batch_id)\n",
    "     .option(\"txnAppId\", app_id)\n",
    "     .save(\"/opt/workspace/data/delta_lake/idempotent-stream-write-delta/user_americas\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "087b6d77-97ae-4b77-b39c-42a039d05d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                         (0 + 2) / 50]\r"
     ]
    }
   ],
   "source": [
    "# 적용 the function against the micro-batches using ‘foreachBatch’\n",
    "write_query = (df\n",
    " .writeStream  # 스트리밍 데이터 쓰기\n",
    " .format(\"delta\")  # Delta Lake 형식으로 저장\n",
    " .queryName(\"Users By Region\")\n",
    " .foreachBatch(writeToDeltaLakeTableIdempotent)\n",
    " .start()  # 스트리밍 시작)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db57b70b-7939-4c00-b0ca-3928076f9839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">count(1)</td></tr><tr><td>44</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT COUNT(*) FROM delta.`/opt/workspace/data/delta_lake/idempotent-stream-write-delta/user_asia`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "280d8499-70ff-46a8-bce4-3645a88bc099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">count(1)</td></tr><tr><td>65</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT COUNT(*) FROM delta.`/opt/workspace/data/delta_lake/idempotent-stream-write-delta/user_americas`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5939de1f-2bcd-4f08-827f-5c13d46ad05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">count(1)</td></tr><tr><td>45</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 147:====>                                                   (4 + 2) / 50]\r"
     ]
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT COUNT(*) FROM delta.`/opt/workspace/data/delta_lake/idempotent-stream-write-delta/user_asia`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "176b9fbf-ded7-49a1-90eb-1b9635a27f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">count(1)</td></tr><tr><td>68</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT COUNT(*) FROM delta.`/opt/workspace/data/delta_lake/idempotent-stream-write-delta/user_americas`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4851e696-46cf-4371-aa44-afda5e110cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()\n",
    "write_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49bcfa1b-1401-4af6-a031-c5e17e4ad8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()  # Spark 세션 종료 - 리소스 정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6779dfbf-4561-475a-997f-f951b6418093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}